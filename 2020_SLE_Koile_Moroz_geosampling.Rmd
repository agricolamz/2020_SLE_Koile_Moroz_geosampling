---
title: "Detecting linguistic variation with geographic sampling"
author: "Ezequiel Koile, George Moroz"
institute: "Linguistic Convergence Laboratory, NRU HSE"
date: |
    | 26 August 2020
    |
    |    
    | Presentation is available here: \alert{tinyurl.com/y7kjsp67}
    | ![](images/00_qrcode.png)'
output: 
  beamer_presentation:
    df_print: kable
    latex_engine: xelatex
    citation_package: natbib
    keep_tex: false
    includes:
      in_header: "config/presento.sty"
bibliography: bibliography.bib
biblio-style: "apalike"
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
options(digits = 2)
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
# library(qrcode)
# png(filename="images/00_qrcode.png", width = 200, height = 200)
# qrcode_gen("https://github.com/agricolamz/2020_SLE_Koile_Moroz_geosampling/raw/master/2020_SLE_Koile_Moroz_geosampling.pdf")
# dev.off()
library(tidyverse)
library(broom)
library(ggeffects)
theme_set(theme_bw()+
            theme(text = element_text(size = 15),
                  legend.position="bottom"))
generated_data <- read_csv("data/generated_data.csv")
generated_data %>% 
  mutate(type = ifelse(type == "random", "uniform", type),
         type = factor(type, levels = c("uniform", "equadistant", "central-periphery"))) ->
  generated_data
all_results <- read_csv("data/all_results.csv")
all_results %>% 
  mutate(type = ifelse(type == "random", "uniform", type),
         type = factor(type, levels = c("uniform", "equadistant", "central-periphery")),
         cluster_type = factor(cluster_type, levels = c("random", "k-means", "hierarchical clustering")),
         ratio_binary = ifelse(ratio == 1, 1, 0)) ->
  all_results
```

# Introduction

## Introduction

* Geolectal variation is often present in settings where one language is spoken across a vast geographic area [@labov1963social].
* It can be found in phonological, morphosyntactic, and lexical features. 
* Could be overlooked by linguists [@dorian10].

# The problem

## The problem

* Let us consider a geographical dialect continuum formed by a group of small villages [@chambers2004dialectology: 5--7]

* We are interested in spotting variation of a discrete parameter among the lects spoken on these villages

```{r, fig.height=5}
library(lingtypology)
map.feature(languages = circassian$language,
            features = circassian$language,
            latitude = circassian$latitude,
            longitude = circassian$longitude, 
            minimap = TRUE,
            minimap.position = "topright",
            legend.position = "bottomleft",
            tile = "Esri.WorldTopoMap")
```

## The problem

* We will very unlikely be able to conduct fieldwork in each single village. Therefore, we need to choose a *sample* of locations.

* *Research Question*: How to choose the sample of villages to survey? 
    1) How many villages is enough for detecting all variation present? (number of categories)
    2) Given an amount of sampled villages, how to decide which ones are representative of our population?

```{r, fig.height=5}
map.feature(languages = circassian$language,
            features = circassian$dialect,
            latitude = circassian$latitude,
            longitude = circassian$longitude, 
            minimap = TRUE,
            minimap.position = "topright",
            legend.position = "bottomleft",
            tile = "Esri.WorldTopoMap")
```


# Our approach

## Our approach

* We want to find the distribution of variation for one feature, and we try different ways of choosing the sampled villages for finding it

* As we assume we don't have any data beyond the geographic location of each village, we use these locations for building our sample

* We generate clusters with different algorithms (k-means, hierarchical clustering) and pick our sampled locations based on them (package stats, [@rteam]).

* We compare our results against random sampling in two different scenarios, both for simulated and for real Circassian data: 
    * Multiple categorical data (detect variation)
    * Binary categorical data (estimate variation)

# Simulated data

## Simulated data

* total number of locations (*N*): $30, 50, 70$
* type of spatial relations:
    * uniformly distributed
    * equadistant -- ...
    * central and periphery
* number of categories (???): $3, 4, 5$
* proportion of categories (???): e. g. $20-16-14, 9-8-7-5-1$
* proportion of variation in the explored variable ($p$): $0.05, 0.10 \dots 0.90$
* amount of clusters ($k$): $N\times0.05, N\times0.10, \dots N\times0.90$

From  those values we could derive a number of sampled locations ($n$):

$$n = N\times r$$

## Example of different number of locations (*N*)

```{r}
set.seed(42)
generated_data %>% 
  group_by(n_villages) %>% 
  sample_n(1) %>% 
  ungroup() %>% 
  select(dataset_id) %>% 
  unlist() %>% 
  unname() ->
  select_n_villages

generated_data %>% 
  filter(dataset_id %in% select_n_villages) %>% 
  ggplot(aes(x, y))+
  geom_point()+
  facet_wrap(~n_villages, nrow = 2)+
  labs(x = "", y = "")+
  theme(axis.text = element_blank(),
        axis.ticks = element_blank())
```


## Example of different number of categories

```{r}
set.seed(42)
generated_data %>% 
  group_by(n_category) %>% 
  sample_n(1) %>% 
  ungroup() %>% 
  select(dataset_id) %>% 
  unlist() %>% 
  unname() ->
  select_n_category

generated_data %>% 
  filter(dataset_id %in% select_n_category) %>% 
  ggplot(aes(x, y, color = value, shape = value))+
  geom_point(size = 2)+
  facet_wrap(~n_category, nrow = 2)+
  labs(x = "", y = "", color = "")+
  theme(axis.text = element_blank(),
        axis.ticks = element_blank())+
  scale_shape_manual("", values=c(15,16,17,18, 8))
```


## Example of different proportion of categories

```{r}
set.seed(42)
generated_data %>% 
  filter(n_category == 4, n_villages == 30) %>% 
  group_by(vars) %>% 
  sample_n(1) %>% 
  ungroup() %>%
  sample_n(4) %>% 
  select(dataset_id) %>% 
  unlist() %>% 
  unname() ->
  select_vars

generated_data %>% 
  filter(dataset_id %in% select_vars) %>% 
  ggplot(aes(x, y, color = value, shape = value))+
  geom_point(size = 2)+
  facet_wrap(~vars, nrow = 2)+
  labs(x = "", y = "", color = "")+
  theme(axis.text = element_blank(),
        axis.ticks = element_blank())+
  scale_shape_manual("", values=c(15,16,17,18))
```

## Example of different types of spatial relations

```{r}
set.seed(42)
generated_data %>% 
  filter(n_category == 4, n_villages == 70, vars == "22-18-17-13") %>% 
  group_by(type) %>% 
  sample_n(1) %>% 
  ungroup() %>%
  select(dataset_id) %>% 
  unlist() %>% 
  unname() ->
  select_type

generated_data %>% 
  filter(dataset_id %in% select_type) %>% 
  ggplot(aes(x, y, color = value, shape = value))+
  geom_point(size = 2)+
  stat_ellipse()+
  facet_wrap(~type, nrow = 2)+
  labs(x = "", y = "", color = "")+
  theme(axis.text = element_blank(),
        axis.ticks = element_blank())+
  scale_shape_manual("", values=c(15,16,17,18))

# df %>% 
#   filter(N == 120, p == 0.4, r == 0.1) %>% 
#   mutate(spatial_relations = factor(spatial_relations, levels = c("random", "two_regions", "central_periphery"), labels = c("random", "two regions", "central-periphery"))) %>% 
#   ggplot(aes(x, y, color = value, shape = value, shape = value))+
#   stat_ellipse(alpha = 0.2)+
#   geom_point()+
#   facet_wrap(~spatial_relations, scale = "free", nrow = 2)+
#   labs(x = "", y = "")+
#   theme(axis.text = element_blank(),
#         axis.ticks = element_blank())
```


# Results and modelling

## Results

* Plots of fitting with different parameters

## Modelling the variation

* We want to account quantitatively for the improvement of our fitting according to the different parameters present

* We model a logistic regression (values: all variation discovered / not all variation discovered), with the following parameters modifying the independent variable 

  * Type of clustering (hirarchical, K-means, random)
  * Amount of categories (numeric: 3,4,5)
  * Type of geographic distribution (central-periphery, separated clusters, random)
  * Amount of total villages (numeric: 30, 50, 70)
  * Entropy (numeric)
  
## Results

```{r}
fit_1 <- glm(ratio_binary ~ (type+cluster_type)*proportion_of_village, 
             family = "binomial",
             data=all_results)

tidy(fit_1) %>% 
  knitr::kable()
```

## Results
```{r}
ggeffect(fit_1, terms = c("proportion_of_village", "cluster_type", "type")) %>% 
  plot()
```
  
  
# Circassian data example

# Entropy

## Information entropy

In order to measure the diversity of the questions we used the easiest measure --- information entropy, introduced in [@shannon48]:

$$H(X) = - \sum_{i = 1}^n{P(x_i)\times\log_2P(x_i)}$$
\pause

The range of the information entropy is $H(X) \in [0, +\infty]$: 

```{r}
tibble(a = c("A", "A", "A", "A", "B"),
       b = c("A", "A", "A", "B", "B"),
       c = c("A", "A", "B", "B", "B"),
       e = c("A", "A", "B", "B", "C"),
       f = c("A", "B", "C", "A", "B"),
       g = c("A", "A", "A", "A", "A"), 
       h = c("A", "B", "C", "D", "E")) %>% 
  pivot_longer(names_to = "id", values_to = "value", a:h) %>% 
  group_by(id) %>% 
  mutate(data = str_c(value, collapse = "-")) %>% 
  count(data, value) %>% 
  mutate(ratio = n/sum(n)) %>% 
  group_by(data) %>% 
  summarise(entropy = round(-sum(ratio*log2(ratio)), 2)) %>% 
  arrange(entropy) %>% 
  knitr::kable()
```

## Information entropy: simulated data

```{r}
all_results %>%   
  ggplot(aes(H, ratio, linetype = factor(n_category), color = cluster_type))+
  #geom_jitter(alpha = 0.2, size = 0.7)+
  geom_smooth(se = FALSE)+
  scale_linetype_manual("", values=c(1,2,4))+
  labs(x = "entropy", color = "", linetype = "")
```


# Conclusions

## Conclusions


# References {.allowframebreaks}
